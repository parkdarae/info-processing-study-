#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë‹¨ì–´ì¥ ë¶ˆì¼ì¹˜ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ë¬¸ì œì—ì„œ ë‹¨ì¼ ë‹¨ì–´ë¡œ ì‚¬ìš©ëœ ê²½ìš°ë§Œ í™•ì¸í•˜ì—¬ ì •í™•í•œ ìˆ˜ì • ëª©ë¡ ìƒì„±
"""

import json
import sys
from pathlib import Path

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    vocab_file = project_root / 'data' / 'cissp_vocabulary.json'
    items_file = project_root / 'data' / 'items_cissp.jsonl'
    issues_file = project_root / 'data' / 'vocabulary_issues.json'
    
    with open(vocab_file, 'r', encoding='utf-8') as f:
        vocabulary = json.load(f)
    
    items = []
    with open(items_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                items.append(json.loads(line))
    
    with open(issues_file, 'r', encoding='utf-8') as f:
        issues = json.load(f)
    
    return vocabulary, items, issues

def find_exact_word_matches(items):
    """ì„ íƒì§€ê°€ ì •í™•íˆ ë‹¨ì¼ ë‹¨ì–´ì¸ ê²½ìš°ë§Œ ì°¾ê¸°"""
    exact_matches = {}  # {word: [translations]}
    
    for item in items:
        if 'choices_en' in item and 'choices_ko' in item:
            choices_en = item['choices_en']
            choices_ko = item['choices_ko']
            
            if isinstance(choices_en, dict) and isinstance(choices_ko, dict):
                for key in choices_en.keys():
                    choice_en = choices_en.get(key, '').strip()
                    choice_ko = choices_ko.get(key, '').strip()
                    
                    # ì„ íƒì§€ê°€ ë‹¨ì¼ ë‹¨ì–´ì´ê³  ì§§ì€ ê²½ìš° (30ì ì´í•˜, ê³µë°± ì—†ìŒ)
                    if choice_en and choice_ko and len(choice_en) <= 30:
                        # ê³µë°±, í•˜ì´í”ˆ, ê´„í˜¸ê°€ ì—†ëŠ” ìˆœìˆ˜ ë‹¨ì–´ì¸ì§€ í™•ì¸
                        clean_en = choice_en.replace('-', '').replace(' ', '').replace('(', '').replace(')', '')
                        if clean_en.isalpha() or (clean_en.replace('.', '').replace('/', '').isalnum() and len(choice_en.split()) == 1):
                            word = choice_en.lower().strip()
                            if word not in exact_matches:
                                exact_matches[word] = []
                            if choice_ko not in exact_matches[word]:
                                exact_matches[word].append(choice_ko)
    
    return exact_matches

def analyze_issues():
    """ë¶ˆì¼ì¹˜ ë¶„ì„"""
    vocabulary, items, issues = load_data()
    
    print("=" * 60)
    print("ë‹¨ì–´ì¥ ë¶ˆì¼ì¹˜ ë¶„ì„ ë° ìˆ˜ì • ëª©ë¡")
    print("=" * 60)
    
    # ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ ì°¾ê¸°
    print("\n1. ì‹¤ì œ ë¬¸ì œì—ì„œ ë‹¨ì¼ ë‹¨ì–´ë¡œ ì‚¬ìš©ëœ ê²½ìš° í™•ì¸ ì¤‘...")
    exact_matches = find_exact_word_matches(items)
    print(f"   {len(exact_matches)}ê°œ ë‹¨ì–´ì˜ ì •í™•í•œ ë²ˆì—­ ë°œê²¬")
    
    # ë¶ˆì¼ì¹˜ ëª©ë¡ ë¶„ì„
    print("\n2. ë¶ˆì¼ì¹˜ ëª©ë¡ ë¶„ì„ ì¤‘...")
    
    real_issues = []  # ì‹¤ì œ ìˆ˜ì •ì´ í•„ìš”í•œ í•­ëª©
    false_positives = []  # ì˜ëª»ëœ ë§¤ì¹­ (ë¬´ì‹œ ê°€ëŠ¥)
    
    for issue in issues:
        word = issue['word']
        vocab_meaning = issue['vocab']
        actual_trans = issue['actual']
        
        # ì •í™•í•œ ë§¤ì¹­ì—ì„œ í•´ë‹¹ ë‹¨ì–´ ì°¾ê¸°
        if word.lower() in exact_matches:
            exact_trans = exact_matches[word.lower()]
            
            # ì •í™•í•œ ë²ˆì—­ê³¼ ë¹„êµ
            if vocab_meaning not in exact_trans:
                # ì‹¤ì œë¡œ ìˆ˜ì •ì´ í•„ìš”í•œ ê²½ìš°
                real_issues.append({
                    'word': word,
                    'current': vocab_meaning,
                    'should_be': exact_trans[0] if exact_trans else vocab_meaning,
                    'all_uses': exact_trans
                })
            else:
                # ë‹¨ì–´ì¥ì´ ë§ëŠ” ê²½ìš° (ë‹¤ë¥¸ ì˜ë¯¸ë¡œë„ ì‚¬ìš©ë¨)
                false_positives.append({
                    'word': word,
                    'vocab': vocab_meaning,
                    'actual': actual_trans,
                    'note': 'ì •í™•í•œ ë§¤ì¹­ì—ì„œëŠ” ì¼ì¹˜í•¨'
                })
        else:
            # ì •í™•í•œ ë§¤ì¹­ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
            # ëŒ€ë¶€ë¶„ ì˜ëª»ëœ ë§¤ì¹­ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            false_positives.append({
                'word': word,
                'vocab': vocab_meaning,
                'actual': actual_trans,
                'note': 'ë‹¨ì¼ ë‹¨ì–´ë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (ì˜ëª»ëœ ë§¤ì¹­ ê°€ëŠ¥ì„±)'
            })
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“‹ ìˆ˜ì •ì´ í•„ìš”í•œ ë‹¨ì–´ ëª©ë¡")
    print("=" * 60)
    
    if real_issues:
        print(f"\nì´ {len(real_issues)}ê°œ ë‹¨ì–´ ìˆ˜ì • í•„ìš”:\n")
        for i, issue in enumerate(real_issues, 1):
            print(f"{i}. {issue['word']}")
            print(f"   í˜„ì¬: {issue['current']}")
            print(f"   ìˆ˜ì •: {issue['should_be']}")
            if len(issue['all_uses']) > 1:
                print(f"   (ë‹¤ë¥¸ ì‚¬ìš©: {', '.join(issue['all_uses'][1:])})")
            print()
    else:
        print("\nìˆ˜ì •ì´ í•„ìš”í•œ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì˜ëª»ëœ ë§¤ì¹­ ëª©ë¡ (ì°¸ê³ ìš©)
    if false_positives:
        print("\n" + "=" * 60)
        print("â„¹ï¸  ì˜ëª»ëœ ë§¤ì¹­ìœ¼ë¡œ íŒë‹¨ëœ í•­ëª© (ë¬´ì‹œ ê°€ëŠ¥)")
        print("=" * 60)
        print(f"\nì´ {len(false_positives)}ê°œ í•­ëª©\n")
        for i, fp in enumerate(false_positives[:10], 1):
            print(f"{i}. {fp['word']}")
            print(f"   ë‹¨ì–´ì¥: {fp['vocab']}")
            print(f"   ì˜ëª» ë§¤ì¹­ëœ ë²ˆì—­: {fp['actual']}")
            print(f"   ì°¸ê³ : {fp['note']}")
            print()
        if len(false_positives) > 10:
            print(f"... ì™¸ {len(false_positives) - 10}ê°œ ë” ìˆìŒ")
    
    # ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    if real_issues:
        print("\n" + "=" * 60)
        print("ğŸ’¾ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")
        print("=" * 60)
        
        fixes = []
        for issue in real_issues:
            fixes.append({
                'word': issue['word'],
                'old': issue['current'],
                'new': issue['should_be']
            })
        
        output_file = project_root / 'data' / 'vocabulary_fixes.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(fixes, f, ensure_ascii=False, indent=2)
        
        print(f"\nìˆ˜ì • ëª©ë¡ì´ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("\nìˆ˜ì •í•  ë‹¨ì–´ ëª©ë¡:")
        for fix in fixes:
            print(f"  - {fix['word']}: '{fix['old']}' â†’ '{fix['new']}'")
    
    return real_issues

if __name__ == '__main__':
    project_root = Path(__file__).parent.parent
    analyze_issues()

