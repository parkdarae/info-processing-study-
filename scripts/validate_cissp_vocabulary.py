#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CISSP ë‹¨ì–´ì¥ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
items_cissp.jsonlì˜ ì‹¤ì œ ë²ˆì—­ê³¼ cissp_vocabulary.jsonì˜ ë²ˆì—­ì„ ë¹„êµí•˜ì—¬
ë¶ˆì¼ì¹˜í•˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆëŠ” ë²ˆì—­ì„ ì°¾ìŠµë‹ˆë‹¤.
"""

import json
import re
import sys
from collections import defaultdict
from pathlib import Path

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

def normalize_word(word):
    """ë‹¨ì–´ ì •ê·œí™” (ì†Œë¬¸ì, íŠ¹ìˆ˜ë¬¸ì ì œê±°)"""
    return word.lower().strip().replace(' ', '').replace('-', '').replace('_', '')

def extract_words_from_text(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì˜ì–´ ë‹¨ì–´ ì¶”ì¶œ"""
    if not text:
        return []
    
    # ì†Œë¬¸ì ë³€í™˜ ë° íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
    text = re.sub(r'[^\w\s-]', ' ', text.lower())
    text = re.sub(r'-', ' ', text)
    
    # ë‹¨ì–´ ì¶”ì¶œ (ì•ŒíŒŒë²³ë§Œ, ìµœì†Œ 2ê¸€ì)
    words = re.findall(r'\b[a-z]{2,}\b', text)
    return words

def load_vocabulary(vocab_file):
    """ë‹¨ì–´ì¥ ë¡œë“œ"""
    if not Path(vocab_file).exists():
        print(f"ê²½ê³ : {vocab_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    with open(vocab_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_items(items_file):
    """ë¬¸ì œ ë°ì´í„° ë¡œë“œ"""
    items = []
    with open(items_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                items.append(json.loads(line))
    return items

def find_word_in_choices(word, choices_en, choices_ko):
    """ì„ íƒì§€ì—ì„œ ë‹¨ì–´ë¥¼ ì°¾ê³  í•´ë‹¹ í•œêµ­ì–´ ë²ˆì—­ ë°˜í™˜"""
    word_lower = word.lower()
    
    for key in choices_en.keys():
        choice_en = choices_en.get(key, '')
        choice_ko = choices_ko.get(key, '')
        
        # ì„ íƒì§€ í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ ì°¾ê¸°
        if word_lower in choice_en.lower():
            return choice_ko
    
    return None

def validate_vocabulary():
    """ë‹¨ì–´ì¥ ê²€ì¦"""
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    vocab_file = project_root / 'data' / 'cissp_vocabulary.json'
    items_file = project_root / 'data' / 'items_cissp.jsonl'
    
    print("=" * 60)
    print("CISSP ë‹¨ì–´ì¥ ê²€ì¦ ì‹œì‘")
    print("=" * 60)
    
    # ë‹¨ì–´ì¥ ë¡œë“œ
    print(f"\n1. ë‹¨ì–´ì¥ ë¡œë“œ ì¤‘: {vocab_file}")
    vocabulary = load_vocabulary(vocab_file)
    print(f"   ì´ {len(vocabulary)}ê°œ ë‹¨ì–´ ë¡œë“œë¨")
    
    # ë¬¸ì œ ë°ì´í„° ë¡œë“œ
    print(f"\n2. ë¬¸ì œ ë°ì´í„° ë¡œë“œ ì¤‘: {items_file}")
    items = load_items(items_file)
    print(f"   ì´ {len(items)}ê°œ ë¬¸ì œ ë¡œë“œë¨")
    
    # ë¬¸ì œì—ì„œ ì‹¤ì œ ì‚¬ìš©ëœ ë‹¨ì–´-ë²ˆì—­ ë§¤í•‘ ìˆ˜ì§‘
    print(f"\n3. ë¬¸ì œì—ì„œ ì‹¤ì œ ì‚¬ìš©ëœ ë²ˆì—­ ìˆ˜ì§‘ ì¤‘...")
    actual_translations = defaultdict(set)  # {word: {translation1, translation2, ...}}
    
    for item in items:
        # question_enê³¼ question_ko ë¹„êµ
        if 'question_en' in item and 'question_ko' in item:
            question_words = extract_words_from_text(item['question_en'])
            # ì „ì²´ ì§ˆë¬¸ì— ëŒ€í•œ ë²ˆì—­ì€ ë‹¨ì–´ë³„ë¡œ ë§¤í•‘í•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ ìŠ¤í‚µ
        
        # choices_enê³¼ choices_ko ë¹„êµ
        if 'choices_en' in item and 'choices_ko' in item:
            choices_en = item['choices_en']
            choices_ko = item['choices_ko']
            
            if isinstance(choices_en, dict) and isinstance(choices_ko, dict):
                for key in choices_en.keys():
                    choice_en = choices_en.get(key, '').strip()
                    choice_ko = choices_ko.get(key, '').strip()
                    
                    if choice_en and choice_ko:
                        # ì„ íƒì§€ ì „ì²´ê°€ ë‹¨ì–´ì¸ ê²½ìš°ë§Œ ë§¤ì¹­ (ì˜ˆ: "Privacy", "Availability", "Confidentiality")
                        # ì„ íƒì§€ê°€ ì§§ê³ (30ì ì´í•˜) ë‹¨ì–´ì²˜ëŸ¼ ë³´ì´ëŠ” ê²½ìš°
                        choice_en_normalized = normalize_word(choice_en)
                        
                        # ì„ íƒì§€ê°€ ë‹¨ì¼ ë‹¨ì–´ì´ê±°ë‚˜ ë§¤ìš° ì§§ì€ ê²½ìš°
                        if len(choice_en) <= 30 and not ' ' in choice_en.strip():
                            # ë‹¨ì¼ ë‹¨ì–´ë¡œ ì²˜ë¦¬
                            word = choice_en.strip().lower()
                            actual_translations[word].add(choice_ko)
                        elif len(choice_en) <= 50:
                            # ì§§ì€ ì„ íƒì§€ì—ì„œ ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ ì‹œë„
                            # í•˜ì§€ë§Œ ì •í™•í•œ ë§¤ì¹­ë§Œ (ì„ íƒì§€ ì „ì²´ê°€ ë‹¨ì–´ì¸ ê²½ìš°)
                            words_in_choice = extract_words_from_text(choice_en)
                            for word in words_in_choice:
                                # ì„ íƒì§€ê°€ ë‹¨ì¼ ë‹¨ì–´ì¸ ê²½ìš°ë§Œ
                                if normalize_word(choice_en) == normalize_word(word) and len(choice_en.split()) == 1:
                                    actual_translations[word].add(choice_ko)
    
    print(f"   {len(actual_translations)}ê°œ ë‹¨ì–´ì˜ ì‹¤ì œ ë²ˆì—­ ìˆ˜ì§‘ë¨")
    
    # ê²€ì¦ ì‹œì‘
    print(f"\n4. ë‹¨ì–´ì¥ ê²€ì¦ ì¤‘...")
    print("=" * 60)
    
    issues = []
    exact_matches = []
    partial_matches = []
    no_matches = []
    
    for word, vocab_data in vocabulary.items():
        vocab_meaning = vocab_data.get('meaning', '').strip()
        
        if not vocab_meaning:
            issues.append({
                'word': word,
                'type': 'empty_meaning',
                'message': 'ì˜ë¯¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'
            })
            continue
        
        # ì‹¤ì œ ì‚¬ìš©ëœ ë²ˆì—­ í™•ì¸
        actual_trans = actual_translations.get(word.lower())
        
        if not actual_trans:
            # ì‹¤ì œ ë¬¸ì œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šì€ ë‹¨ì–´
            no_matches.append(word)
            continue
        
        # ì‹¤ì œ ë²ˆì—­ê³¼ ë‹¨ì–´ì¥ ë²ˆì—­ ë¹„êµ
        actual_trans_list = list(actual_trans)
        
        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        exact_match = False
        partial_match = False
        
        for trans in actual_trans_list:
            # ì •í™•íˆ ì¼ì¹˜
            if vocab_meaning == trans:
                exact_match = True
                break
            # ë¶€ë¶„ ì¼ì¹˜ (ë‹¨ì–´ì¥ì— ì—¬ëŸ¬ ì˜ë¯¸ê°€ ìˆì„ ìˆ˜ ìˆìŒ)
            elif trans in vocab_meaning or vocab_meaning in trans:
                partial_match = True
        
        if exact_match:
            exact_matches.append({
                'word': word,
                'vocab': vocab_meaning,
                'actual': actual_trans_list
            })
        elif partial_match:
            partial_matches.append({
                'word': word,
                'vocab': vocab_meaning,
                'actual': actual_trans_list
            })
        else:
            # ë¶ˆì¼ì¹˜
            issues.append({
                'word': word,
                'type': 'mismatch',
                'vocab': vocab_meaning,
                'actual': actual_trans_list,
                'message': f'ë‹¨ì–´ì¥: "{vocab_meaning}" vs ì‹¤ì œ: {actual_trans_list}'
            })
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼")
    print("=" * 60)
    print(f"âœ… ì •í™•íˆ ì¼ì¹˜: {len(exact_matches)}ê°œ")
    print(f"âš ï¸  ë¶€ë¶„ ì¼ì¹˜: {len(partial_matches)}ê°œ")
    print(f"âŒ ë¶ˆì¼ì¹˜: {len(issues)}ê°œ")
    print(f"â„¹ï¸  ì‹¤ì œ ì‚¬ìš© ì•ˆ ë¨: {len(no_matches)}ê°œ")
    
    # ë¶ˆì¼ì¹˜ ìƒì„¸ ì¶œë ¥
    if issues:
        print(f"\nâŒ ë¶ˆì¼ì¹˜í•˜ëŠ” ë‹¨ì–´ ({len(issues)}ê°œ):")
        print("-" * 60)
        for issue in issues[:20]:  # ìµœëŒ€ 20ê°œë§Œ í‘œì‹œ
            print(f"  â€¢ {issue['word']}")
            print(f"    ë‹¨ì–´ì¥: {issue['vocab']}")
            print(f"    ì‹¤ì œ: {', '.join(issue['actual'])}")
            print()
        
        if len(issues) > 20:
            print(f"  ... ì™¸ {len(issues) - 20}ê°œ ë” ìˆìŒ")
    
    # ë¶€ë¶„ ì¼ì¹˜ ìƒì„¸ ì¶œë ¥
    if partial_matches:
        print(f"\nâš ï¸  ë¶€ë¶„ ì¼ì¹˜í•˜ëŠ” ë‹¨ì–´ ({len(partial_matches)}ê°œ, ìµœëŒ€ 10ê°œ í‘œì‹œ):")
        print("-" * 60)
        for match in partial_matches[:10]:
            print(f"  â€¢ {match['word']}")
            print(f"    ë‹¨ì–´ì¥: {match['vocab']}")
            print(f"    ì‹¤ì œ: {', '.join(match['actual'])}")
            print()
    
    # ì˜ë¯¸ê°€ ë¹„ì–´ìˆëŠ” ë‹¨ì–´
    empty_meanings = [i for i in issues if i['type'] == 'empty_meaning']
    if empty_meanings:
        print(f"\nâš ï¸  ì˜ë¯¸ê°€ ë¹„ì–´ìˆëŠ” ë‹¨ì–´ ({len(empty_meanings)}ê°œ):")
        print("-" * 60)
        for issue in empty_meanings[:10]:
            print(f"  â€¢ {issue['word']}")
    
    # ì‹¤ì œ ì‚¬ìš©ë˜ì§€ ì•Šì€ ë‹¨ì–´
    if no_matches:
        print(f"\nâ„¹ï¸  ì‹¤ì œ ë¬¸ì œì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šì€ ë‹¨ì–´ ({len(no_matches)}ê°œ, ìµœëŒ€ 20ê°œ í‘œì‹œ):")
        print("-" * 60)
        for word in sorted(no_matches)[:20]:
            print(f"  â€¢ {word}")
        if len(no_matches) > 20:
            print(f"  ... ì™¸ {len(no_matches) - 20}ê°œ ë” ìˆìŒ")
    
    # ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“‹ ìš”ì•½")
    print("=" * 60)
    print(f"ì´ ë‹¨ì–´ ìˆ˜: {len(vocabulary)}")
    print(f"ì‹¤ì œ ì‚¬ìš©ëœ ë‹¨ì–´: {len(actual_translations)}")
    print(f"ì •í™•íˆ ì¼ì¹˜: {len(exact_matches)} ({len(exact_matches)/len(actual_translations)*100:.1f}%)")
    print(f"ë¶€ë¶„ ì¼ì¹˜: {len(partial_matches)} ({len(partial_matches)/len(actual_translations)*100:.1f}%)")
    print(f"ë¶ˆì¼ì¹˜: {len(issues)} ({len(issues)/len(actual_translations)*100:.1f}%)")
    
    # ë¶ˆì¼ì¹˜ ëª©ë¡ì„ íŒŒì¼ë¡œ ì €ì¥
    if issues:
        output_file = project_root / 'data' / 'vocabulary_issues.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(issues, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ë¶ˆì¼ì¹˜ ëª©ë¡ì´ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print("\nâœ… ê²€ì¦ ì™„ë£Œ!")

if __name__ == '__main__':
    validate_vocabulary()

